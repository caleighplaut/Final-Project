---
title: "Final Project"
author: "Meredith Manley and Caleigh Plaut"
date: "11/16/17"
output: 
  html_document:
    fig_height: 3
    fig_width: 5
  pdf_document:
    fig_height: 3
    fig_width: 5
  word_document:
    fig_height: 3
    fig_width: 5
---

```{r, setup, include=FALSE}
require(mosaic)   # Load additional packages here 

# Some customization.  You can alter or delete as desired (if you know what you are doing).
trellis.par.set(theme=theme.mosaic()) # change default color scheme for lattice
knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```



# Data Collection
```{r}
# Load the necessary packages
library(tidyverse)
library(httr)
library(yelpr)
library(glmnet)
library(dplyr)
library(ggplot2)
library(ggmap)

# Code provided by Alex to obtain data from Yelp API
devtools::install_github("jennybc/ryelp")
res <- POST("https://api.yelp.com/oauth2/token",
            body = list(grant_type = "client_credentials",
                        client_id = "t5Vxmm0MO0Cb6FV6y7RfOg",
                        client_secret = "CnukNBSKQMF1CNNk9BGX8H1ZCj4JwYdRnZmiaZkBbelBHD8Q9lZhZTaGuyAahZqS"))
token <- content(res)$access_token

# Looking at restaurants in the top 10 largest cities in the US
yelp <- "https://api.yelp.com"
term <- "restaurant"
location <- c("New York City, NY", "Los Angeles, CA", "Chicago, IL", "Houston,TX", "Philadelphia, PA",
              "Phoenix, AZ", "San Antonio, TX", "San Diego, CA", "Dallas, TX", "San Jose, CA")
us_rest <- as.data.frame(c())

for (i in 1:length(location)) {
  limit <- 50
  (url <-
      modify_url(yelp, path = c("v3", "businesses", "search"),
                 query = list(term = term, location = location[i], limit = limit)))
  
  res <- GET(url, add_headers('Authorization' = paste("bearer", token)))
  http_status(res)
  
  ct <- content(res)
  tmp <- ct$businesses %>%
    map_df(`[`, c("name", "phone", "is_closed", "rating", "distance", "review_count")) %>%
    mutate(price = ct$businesses[[1]][11], city = ct$businesses[[1]][[12]][4], 
           state = ct$businesses[[1]][[12]][7], zipcode = ct$businesses[[1]][[12]][5], 
           latitude = ct$businesses[[1]][[9]][1], longitude = ct$businesses[[1]][[9]][2]) 
  # `price`, `city`, `state`, `zipcode`, `latitude`, `longitude` were lists within a list 
  # so we need to extract that separately.
  
  us_rest <- rbind(us_rest, tmp)
}

# Convert character lists to just characters and numeric lists to just numerical values
us_rest$price <- as.character(us_rest$price)
us_rest$city <- as.character(us_rest$city)
us_rest$state <- as.character(us_rest$state)
us_rest$zipcode <- as.character(us_rest$zipcode)
us_rest$latitude <- as.numeric(us_rest$latitude)
us_rest$longitude <- as.numeric(us_rest$longitude)

# Change `price` from character to ordinal variable
us_rest2 <- us_rest

for (i in length(us_rest2)) {
  
  if(us_rest2$price[i] == "$") {
        us_rest2$price[i] == 1
  } else if (us_rest2$price[i] == "$$") {
    us_rest2$price[i] == 2
  } else if (us_rest2$price[i] == "$$$") {
    us_rest2$price[i] == 3
  } else if (us_rest2$price[i] == "$$$$") {
    us_rest2$price[i] == 4
  } else
    us_rest2$price[i] == 5

}

if(us_rest2$price == "$") {
        us_rest2$price == 1
  } else if (us_rest2$price == "$$") {
    us_rest2$price == 2
  } else if (us_rest2$price == "$$$") {
    us_rest2$price == 3
  } else if (us_rest2$price == "$$$$") {
    us_rest2$price == 4
  } else
    us_rest2$price == 5

# Change `is_closed` from a logical variable to an indicator variable

# Store test results for each model
test_results <- as.data.frame(c())

```


# Exploratory Analysis
```{r}
# trying to predict the rating
qmplot(longitude, latitude, data = us_rest2, colour = I('red'), size = I(3), darken = .3, fullpage=TRUE)
 

us_rest2 %>%
  filter(rating>=3.5) %>%
    ggplot(aes(x=rating))+geom_histogram(stat="bin", binwidth=.5)

us_rest2 %>%
  filter(!is.na(city))%>%
  group_by(city) %>%
    summarise(avg_rating=mean(rating))%>%
      arrange(avg_rating) %>%
        ggplot(aes(x=city, y=avg_rating))+geom_point()


summary(us_rest2$rating)


# what is the average rating of a restaurant grouped by city and price? group by city and review count? other ways to group variables to look at their impact on rating? include a visualization?

# descriptive statistics of the response variable `rating`. include a visualization?



```



# Modeling
### Model 1: Simple Linear Regression
```{r}
# Randomly divide the sample into training and test set
train <- us_rest %>%
  sample_n(450)

test <- us_rest %>%
  anti_join(train, by="phone")
# Matched by unique phone numbers, but needed to include the one location 
# that does not have a phone number.
test <- rbind(test, us_rest[1,])

# Variable selection (???)

# Fit the model
model_formula <- as.formula("rating ~ review_count")
model_lm <- lm(model_formula, data=train)
# Get predictions from test set
y_hat <- predict(model_lm, newdata=test)
test <- mutate(test, y_hat = y_hat)
# Save fitted model and predictions 
fitted_model <- model_lm %>% 
  broom::augment() %>% 
  as_tibble()
predictions <- model_lm %>% 
  broom::augment(newdata=test)
# Plot 
ggplot(NULL) +
  geom_point(data=fitted_model, aes(x=review_count, y=rating)) +
  geom_line(data=fitted_model, aes(x=review_count, y=.fitted), col="blue") +
  geom_point(data=predictions, aes(x=review_count, y=.fitted), col="red") +
  labs(x="Number of Yelp Reviews", y="Rating") + 
  geom_jitter(data=fitted_model, aes(x=review_count, y=rating))

# Determine accuracy of model
test_result <- test %>%
  summarise(MAE = sum(abs(y_hat - rating))/n(),
            MSE = sum((y_hat - rating)^2)/n(),
            SSE = sum((y_hat - rating)^2))
test_result 
test_results <- rbind(test_results, test_result)

```

> Discussion: 


### Model 2: Multiple Linear Regression
```{r}
# Randomly divide the sample into training and test set
train <- us_rest %>%
  sample_n(450)

test <- us_rest %>%
  anti_join(train, by="phone")
# Matched by unique phone numbers, but needed to include the one location 
# that does not have a phone number.
test <- rbind(test, us_rest[1,])

# Variable selection (???)

# Fit the model
model_formula <- as.formula("rating ~ review_count + distance")
model_mlm <- lm(model_formula, data=train)
# Get predictions from test set
y_hat <- predict(model_mlm, newdata=test)
test <- mutate(test, y_hat = y_hat)


# Determine accuracy of model
test_result <- test %>%
  summarise(MAE = sum(abs(y_hat - rating))/n(),
            MSE = sum((y_hat - rating)^2)/n(),
            SSE = sum((y_hat - rating)^2))
test_result 
test_results <- rbind(test_results, test_result)

```

> Discussion:



### Model 3: Spline
```{r}
# Randomly divide the sample into training and test set
train <- us_rest %>%
  sample_n(450)

test <- us_rest %>%
  anti_join(train, by="phone")
# Matched by unique phone numbers, but needed to include the one location 
# that does not have a phone number.
test <- rbind(test, us_rest[1,])

# Variable selection (???)

# Fit the model
model_spline <- smooth.spline(x=train$review_count, y=train$rating, df = 4) 
# play around with degrees of freedom

# Get predictions from test set
y_hat <- predict(model_spline, x=test$review_count)
test <- mutate(test, y_hat = y_hat$y)


# Determine accuracy of model
test_result <- test %>%
  summarise(MAE = sum(abs(y_hat - rating))/n(),
            MSE = sum((y_hat - rating)^2)/n(),
            SSE = sum((y_hat - rating)^2))
test_result 
test_results <- rbind(test_results, test_result)
```

> Discussion:

### Model 4: LASSO
```{r}
# Randomly divide the sample into training and test set
train <- us_rest %>%
  sample_n(450)

test <- us_rest %>%
  anti_join(train, by="phone")
# Matched by unique phone numbers, but needed to include the one location 
# that does not have a phone number.
test <- rbind(test, us_rest[1,])

get_LASSO_coefficients <- function(LASSO_fit){
  coeff_values <- LASSO_fit %>% 
    broom::tidy() %>% 
    as_tibble() %>% 
    select(-c(step, dev.ratio)) %>% 
    tidyr::complete(lambda, nesting(term), fill = list(estimate = 0)) %>% 
    arrange(desc(lambda)) %>% 
    select(term, estimate, lambda)
  return(coeff_values)
}

# Fit the model
model_formula <- as.formula("rating ~ review_count + distance")
predictor_matrix <- model.matrix(model_formula, data = train)[, -1]

lambda_inputs <- 10^seq(-2, 10, length = 100)

LASSO_fit <- glmnet(x=predictor_matrix, y=train$rating, alpha = 1, lambda = lambda_inputs)

# Get coefficients
LASSO_coefficients <- get_LASSO_coefficients(LASSO_fit)

plot_LASSO_coefficients <- LASSO_coefficients %>% 
  filter(term != "(Intercept)") %>% 
  ggplot(aes(x=lambda, y=estimate, col=term)) +
  geom_line() +
  scale_x_log10() +
  labs(x="lambda (log10-scale)", y="beta-hat coefficient estimate",
       title="LASSO regularized coefficient for each lambda value")
plot_LASSO_coefficients

LASSO_CV <- cv.glmnet(x=predictor_matrix, y=train$rating, alpha=1, lambda=lambda_inputs)

# Optimal lambdas
lambda_star <- LASSO_CV$lambda.min
lambda_star_1SE <- LASSO_CV$lambda.1se

plot_LASSO_coefficients <- plot_LASSO_coefficients +
  geom_vline(xintercept = lambda_star, col="red", alpha=0.4, linetype="dashed") +
  geom_vline(xintercept = lambda_star_1SE, col="blue", alpha=0.4, linetype="dashed")
plot_LASSO_coefficients

y_hat <- predict(LASSO_fit, newx=predictor_matrix, s=lambda_star_1SE) %>% 
  as.vector()
mean(y_hat)
```


# Extension
> test on a smaller city (out-of-sample prediction) and see if the best model still does well on a different area. If not, speculate as to why this might be the case.


# Questions
> Change `price` to an ordinal categorical variable
> Change `is_closed` to a binary variable
> Should we treat `rating` as a continous variable or categorical variable
