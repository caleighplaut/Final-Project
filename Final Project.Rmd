---
title: "Write-up for Final Project"
author: "Meredith Manley and Caleigh Plaut"
date: "11/16/17"
output: 
  html_document:
    fig_height: 3
    fig_width: 5
  pdf_document:
    fig_height: 3
    fig_width: 5
  word_document:
    fig_height: 3
    fig_width: 5
---
# Abstract
Our project utilizes the Yelp Fusion API to identify variables that have a meaningful relationship with Yelp rating and incorporate them into a predictive model in the hope of forecasting Yelp rating given a specific restaurant. We narrowed the observations to restaurants in the top ten cities in the United States and further reduced our observations by randomly selecting 50 restaurants from each of these cities, leaving us with 500 observations to work with in total – 450 observations in our training set and 50 observations in our test set. We focused on the relationship between the following variables during our explanatory analysis: distance from the city center and rating, price and rating, and review count and rating. We found that the variable “review count” had a significant correlation with rating and thus would expect that it should be somewhat predictive of “rating.” We decided to use all variables in our initial multivariate linear regression model. Through stepwise linear regression we developed a univariate spline model dependent on “review count” and then again incorporated all variables for our classification algorithm CART model. We found that the spline model performed better than the multivariate linear regression model and that our CART model was correct ___% of the time. 

# Introduction
 



# Data
## Load the Data
```{r}
# Load the necessary packages
library(tidyverse)
library(httr)
library(yelpr)
library(glmnet)
library(MASS)
library(ggplot2)
library(rpart)
library(ggmap)

# Code provided by Alex to obtain data from Yelp API
devtools::install_github("jennybc/ryelp")
res <- POST("https://api.yelp.com/oauth2/token",
            body = list(grant_type = "client_credentials",
                        client_id = "t5Vxmm0MO0Cb6FV6y7RfOg",
                        client_secret = "CnukNBSKQMF1CNNk9BGX8H1ZCj4JwYdRnZmiaZkBbelBHD8Q9lZhZTaGuyAahZqS"))
token <- content(res)$access_token

# Looking at restaurants in the top 10 largest cities in the US
yelp <- "https://api.yelp.com"
term <- "restaurant"
location <- c("New York City, NY", "Los Angeles, CA", "Chicago, IL", "Houston,TX", "Philadelphia, PA",
              "Phoenix, AZ", "San Antonio, TX", "San Diego, CA", "Dallas, TX", "San Jose, CA")
us_rest <- as.data.frame(c())

for (i in 1:length(location)) {
  limit <- 50
  (url <-
      modify_url(yelp, path = c("v3", "businesses", "search"),
                 query = list(term = term, location = location[i], limit = limit)))
  
  res <- GET(url, add_headers('Authorization' = paste("bearer", token)))
  http_status(res)
  
  ct <- content(res)
  tmp <- ct$businesses %>%
    map_df(`[`, c("name", "phone", "is_closed", "rating", "distance", "review_count")) %>%
    mutate(price = ct$businesses[[1]][11], city = ct$businesses[[1]][[12]][4], 
           state = ct$businesses[[1]][[12]][7], zipcode = ct$businesses[[1]][[12]][5], 
           latitude = ct$businesses[[1]][[9]][1], longitude = ct$businesses[[1]][[9]][2]) 
  # `price`, `city`, `state`, `zipcode`, `latitude`, `longitude` were lists within a list 
  # so we need to extract that separately.
  
  us_rest <- rbind(us_rest, tmp)
}

# Convert character lists to just characters and numeric lists to just numerical values
us_rest$price <- as.character(us_rest$price)
us_rest$city <- as.character(us_rest$city)
us_rest$state <- as.character(us_rest$state)
us_rest$zipcode <- as.character(us_rest$zipcode)
us_rest$latitude <- as.numeric(us_rest$latitude)
us_rest$longitude <- as.numeric(us_rest$longitude)

# Change `price` from character to ordinal variable
us_rest <- mutate(us_rest, price_2 = rep(0))

values <- ifelse(us_rest$price == "$", 1, 
       ifelse(us_rest$price == "$$", 2, 
              ifelse(us_rest$price == "$$$", 3, 
                     ifelse(us_rest$price == "$$$$", 4, 5))))

us_rest <- mutate(us_rest, price_2 = values)

# Change `is_closed` from a logical variable to an indicator variable
# where 1 indicated that the restaurant is open and 0 closed
us_rest <- mutate(us_rest, is_open = rep(0))

values <- ifelse(us_rest$is_closed == "FALSE", 1, 0)

us_rest <- mutate(us_rest, is_open = values)
    
# Store test results for each model
test_results <- as.data.frame(c())

```


## Exploratory Analysis
#### Map of 10 Largest Cities in the US
```{r}
qmplot(longitude, latitude, data = us_rest, colour = I('red'), size = I(3), darken = .3, zoom = 5)
``` 

> 



#### Distribution of Outcome Variable  - `rating`
```{r}
us_rest %>%
  filter(rating>=3.5) %>%
    ggplot(aes(x=rating))+geom_histogram(stat="bin", binwidth=.5) + 
    labs(title = "Count of US Restaurants by Respective Rating")
```

> As you can see, most resutrants got a rating of 4.0, which is high since the ratings are 1-5. All restaurant ratings are somewhat bias upwards, so finding one under 4.0 is fairly rare. Also, finding a resutrant with a rating of 5.0 is rare.  Shows the distribution of our outcome variable, which given the limited range of ratings, appears to be fairly normal. Looking at this plot is important because had it been significantly skewed to the right or to the left we may have needed to include some kind of transformation before we began developing our models.


#### Association Between `distance` and `rating`
```{r}
us_rest %>%
        ggplot(aes(x=distance, y=rating)) + geom_point() +
        labs(title = "Association Between Distance and Rating")
```

> The distance variable refers to how far away a given restaurant is from the city that was searched measured in meters regardless of what metric system the desired city uses. One hypothesis that we had was that restaurants that are further from the city center would have a lower rating because they do not experience as much traffic as those downtown and thus may not have as many reviews or customers to rate their experience. From this plot we can see that is it hard to determine if that is true or not.  However, we can see that those restaurants that received the highest rating of 5.0 were all  within approximately 8,000 meters or 5 miles from the searched city and those cities that were furthest away from the searched city received lower ratings of 4.0. This observations are not conclusive in terms of predictability especially given that the correlation between distance and rating is close to zero (-0.007929708), but provide some evidence that we should include this variable in our model development.


#### Association Between `review_count` and `rating` Relative to `price`
```{r}
us_rest %>%
  filter(!is.na(city))%>%
        ggplot(aes(x=review_count, y=rating, color = price_2)) + geom_point(position = "jitter", alpha = 0.4) + labs(title = "Assocation between Review Count and Rating", x = "review count") #+ geom_smooth() 
cor(us_rest$review_count, us_rest$rating)
```

> In this plot we see review count on the x axis and restaurant rating on the y-axis with color indicating the price. This scatterplot differs from the previous plot of the relationship between rating and distance because we have used the jitter feature within the ggplot package so that we can more easily see the different price value for each unique observation. However it does not appear that price varies however remains constant across the plot, so from this graphic it does not appear that price would have a predictive effect on rating. On the other hand, review_count has a moderately strong negative correlation of -0.2554035 with rating and thus we would cautiously say that as review count increases the rating of a given establishment seems to decrease. Given this analysis it would also be beneficial to include this variable in the model development.

# Results


# Diagnostics
### Continuous Outcome Variable

#### Model 1: Multiple Linear Regression
```{r}
set.seed(1)
# Randomly divide the sample into training and test set
train <- us_rest %>%
  sample_n(450)

test <- us_rest %>%
  anti_join(train, by="phone")

# Fit the model
model_formula <- 
  as.formula("rating ~ review_count + distance + is_open + price_2 + latitude + longitude")
model_mlm <- lm(model_formula, data=train)

# calculate train MSE for comparison
y_hat <- predict(model_mlm, newdata=train)
train <- mutate(train, y_hat = y_hat)


# Determine accuracy of model
check <- train %>%
  summarise(MAE = sum(abs(y_hat - rating))/n(),
            MSE = sum((y_hat - rating)^2)/n(),
            SSE = sum((y_hat - rating)^2))
check


# Get predictions from test set
y_hat <- predict(model_mlm, newdata=test)
test <- mutate(test, y_hat = y_hat)


# Determine accuracy of model
test_result <- test %>%
  summarise(MAE = sum(abs(y_hat - rating))/n(),
            MSE = sum((y_hat - rating)^2)/n(),
            SSE = sum((y_hat - rating)^2))
test_result 
test_results <- rbind(test_results, test_result)

# Variable selection with Stepwise Regression
step <- stepAIC(model_mlm, direction="both")
step$anova # display results
```

> Discussion: We decided to start off looking at a model that includes all numeric variables in the training set and compute an initial MSE value from the test set which we can compare with other models. Based on our results we then ran a stepwise regression to determine which model would be the best fit for the data. It turns out that the most accurate linear model only includes `review_count` as a predictor variable, so we will explore the simple linear regression model using `review_count` to predict `rating.` 


#### Model 2: Spline
```{r}
set.seed(3)
# Randomly divide the sample into training and test set
train <- us_rest %>%
  sample_n(450)

test <- us_rest %>%
  anti_join(train, by="phone")

# Fit the model
model_spline <- smooth.spline(x=train$review_count, y=train$rating, df=10) 
# play around with degrees of freedom

# Calculate train MSE for comparison
y_hat <- predict(model_spline, x=train$review_count)
train <- mutate(train, y_hat = y_hat$y)

check <- train %>%
  summarise(MAE = sum(abs(y_hat - rating))/n(),
            MSE = sum((y_hat - rating)^2)/n(),
            SSE = sum((y_hat - rating)^2))
check



# Get predictions from test set
y_hat_test <- predict(model_spline, x=test$review_count)
test <- mutate(test, y_hat = y_hat_test$y)

# plot
fitted_model <- model_spline %>% 
  broom::augment() %>% 
  as_tibble() %>% 
  rename(review_count = x, rating = y)
predictions <- test %>% 
  mutate(.fitted = y_hat)

ggplot(NULL) +
  geom_point(data=fitted_model, aes(x=review_count, y=rating), position = "jitter") +
  geom_line(data=fitted_model, aes(x=review_count, y=.fitted), col="blue") +
  geom_point(data=predictions, aes(x=review_count, y=.fitted), col="red") +
  labs(x="Count of Reviews", y="Rating", title = "Spline Model predicting Rating")

# Determine accuracy of model
# used when determining the appropriate degrees of freedom for this model
MSE <- mean((test$rating - test$y_hat)^2)

test_result <- test %>%
  summarise(MAE = sum(abs(y_hat - rating))/n(),
            MSE = sum((y_hat - rating)^2)/n(),
            SSE = sum((y_hat - rating)^2))
test_result 
test_results <- rbind(test_results, test_result)
```

> Discussion: Explain what is a spline model. Used df=10 because... Does not have a lower MSE value compared to the simple linear regression model


### Categorical Outcome Variable with > 2 levels
#### Model 3: CART
```{r}
set.seed(5)
# Randomly divide the sample into training and test set
train <- us_rest %>%
  sample_n(450)

train$rating[c(21,26, 109, 154, 177, 227, 231, 308, 314)] <- "low"
mutate(train, rating == as.factor(rating))

test <- us_rest %>%
  anti_join(train, by="phone") 
test$rating[8] <- "low"
mutate(test, rating == as.factor(rating))


# Fit the model
model_formula <- 
  as.formula("rating ~ review_count + distance + is_open + price_2 + latitude + longitude + city")
tree_parameters <- rpart.control(maxdepth = 3)
model_CART <- rpart(model_formula, data = train, control=tree_parameters)


# Tree Diagram
plot(model_CART, margin=0.25)
text(model_CART, use.n = TRUE)
title("Predicting Rating using Review Count")
box()

# compare the score of the training set with the test set
p_hat_matrix <- model_CART %>% 
  predict(type = "prob", newdata = train)

y_hat <- model_CART %>% 
  predict(newdata=train, type="class")

# Score/error
MLmetrics::Accuracy(y_true = train$rating, y_pred = y_hat) # getting error because there are 5 levels in the the training set and only 4 levels in the test set
MLmetrics::ConfusionMatrix(y_true = train$rating, y_pred = y_hat)



# predictions on test set
p_hat_matrix <- model_CART %>% 
  predict(type = "prob", newdata = test)

y_hat <- model_CART %>% 
  predict(newdata=test, type="class")

# Score/error
MLmetrics::Accuracy(y_true = test$rating, y_pred = y_hat) 
MLmetrics::ConfusionMatrix(y_true = test$rating, y_pred = y_hat)
```


# Conclusion


